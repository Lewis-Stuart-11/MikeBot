{
  "83": {
    "inputs": {
      "ckpt_name": "film_net_fp32.pt",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "frames": [
        "253",
        0
      ]
    },
    "class_type": "FILM VFI",
    "_meta": {
      "title": "FILM VFI"
    }
  },
  "94": {
    "inputs": {
      "frame_rate": 32,
      "loop_count": 0,
      "filename_prefix": "MikeVideo",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "83",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "218": {
    "inputs": {
      "image": "ComfyUI_00265_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Input Image"
    }
  },
  "229": {
    "inputs": {
      "unet_name": "wan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "231": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "232": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "233": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "236": {
    "inputs": {
      "width": 512,
      "height": 512,
      "length": 73,
      "batch_size": 1,
      "vae": [
        "232",
        0
      ],
      "clip_vision_output": [
        "239",
        0
      ],
      "start_image": [
        "218",
        0
      ],
      "positive": [
        "243",
        0
      ],
      "negative": [
        "244",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "Set Video Length/Width/Height WanImageToVideo"
    }
  },
  "239": {
    "inputs": {
      "crop": "none",
      "clip_vision": [
        "233",
        0
      ],
      "image": [
        "218",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "243": {
    "inputs": {
      "text": "This is filmed on a high quality handheld camera and is in an interview format. A man is sat in an office looking at the camera. He is explaining something with enthusiasm.",
      "clip": [
        "231",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "244": {
    "inputs": {
      "text": "Overexposure, static, blurred details, subtitles, paintings, pictures, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, mutilated, redundant fingers, poorly painted hands, poorly painted faces, deformed, disfigured, deformed limbs, fused fingers, cluttered background, three legs, a lot of people in the background, upside down, red face",
      "clip": [
        "231",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "245": {
    "inputs": {
      "CONDITIONING": [
        "244",
        0
      ]
    },
    "class_type": "Prompts Everywhere",
    "_meta": {
      "title": "Prompts Everywhere"
    }
  },
  "253": {
    "inputs": {
      "tile_size": 256,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "259",
        0
      ],
      "vae": [
        "232",
        0
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "259": {
    "inputs": {
      "seed": 774195909098170,
      "steps": 18,
      "cfg": 3.5,
      "sampler_name": "uni_pc",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "260",
        0
      ],
      "positive": [
        "236",
        0
      ],
      "negative": [
        "236",
        1
      ],
      "latent_image": [
        "236",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "260": {
    "inputs": {
      "shift": 5,
      "model": [
        "229",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "Shift (Default 5)"
    }
  }
}